{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GameLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0CzkTOXKczsT",
        "AKqkxCWpdCMW"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMPco3yPJxf2XuD8NwqwxHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrxon/GameLearning/blob/main/GameLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CzkTOXKczsT"
      },
      "source": [
        "# Program Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwJmSZfObNmZ"
      },
      "source": [
        "Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFqG-9Qo_OQS"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import keras.layers as Kl\n",
        "import keras.models as Km\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo6FDSu7bk3_"
      },
      "source": [
        "Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgJnQ-HqbjxT"
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self, player, params, game, lrnf=0.5, expf=0.8):\n",
        "    self.game = game\n",
        "    self.player = player\n",
        "    self.lrnf = lrnf #lerning factor\n",
        "    self.expf = expf #explore factor\n",
        "    self.prev_state = game.get_state()\n",
        "    self.network = self.init_network(len(game.get_state()), params)\n",
        "\n",
        "  def init_network(self, input, params):\n",
        "    network = Km.Sequential()\n",
        "    network.add(Kl.Dense(params[0], activation='relu', input_dim=input))\n",
        "    for param in params[1:]:\n",
        "      network.add(Kl.Dense(param, activation='relu'))\n",
        "    network.add(Kl.Dense(1, activation='linear'))\n",
        "    network.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "    #network.summary()\n",
        "\n",
        "    return network\n",
        "\n",
        "  def load_model(self, file_name):\n",
        "    try:\n",
        "      new_model = Km.load_model(file_name)\n",
        "    except:\n",
        "      print(\"Wrong file\")\n",
        "      return\n",
        "    self.network = new_model \n",
        "  \n",
        "  def get_model(self):\n",
        "    return self.network\n",
        "\n",
        "  def change_factors(self, lrnf, expf):\n",
        "    if lrnf!=None:\n",
        "      self.lrnf = lrnf\n",
        "    if expf!=None:\n",
        "      self.expf = expf\n",
        "\n",
        "  def get_value(self, move):\n",
        "    if not isinstance(move[0], list):\n",
        "      move = [move]\n",
        "    return self.network.predict(np.array(move))\n",
        "\n",
        "  def get_target(self):\n",
        "    prev_value = self.get_value(self.prev_state)\n",
        "    curr_value = 0\n",
        "    reward = self.game.get_reward(self.player)\n",
        "    if reward == 0:\n",
        "      curr_value = self.get_value(self.game.get_state())\n",
        "    return np.array(prev_value + self.lrnf * (reward + curr_value - prev_value))\n",
        "\n",
        "  def train_network(self):\n",
        "    if not isinstance(self.prev_state[0], list):\n",
        "      self.prev_state = [self.prev_state]\n",
        "    \n",
        "    if self.player in self.game.get_state():\n",
        "      target = self.get_target()\n",
        "      if target is not None:\n",
        "        self.network.fit(np.array(self.prev_state), target, epochs=10, verbose=0)\n",
        "    self.prev_state = self.game.get_state()\n",
        "\n",
        "  def make_move(self, exploit=False, explore=False): #explore/exploit forces behavior\n",
        "    p = random.uniform(0,1)\n",
        "\n",
        "    moves = self.game.get_moves(self.game.get_state(), self.player)\n",
        "\n",
        "    if len(moves) < 1:\n",
        "      return self.game.get_state()\n",
        "\n",
        "    if (p > self.expf or exploit) and not explore:\n",
        "      return self.exploit(moves)\n",
        "    else:\n",
        "      return self.explore(moves)\n",
        "      \n",
        "  def explore(self, moves):\n",
        "    move = random.choice(moves)\n",
        "    return move\n",
        "  \n",
        "  def exploit(self, moves):\n",
        "    move = None\n",
        "    v = -float('Inf')\n",
        "\n",
        "    for temp_move in moves:\n",
        "      v_temp = self.get_value(temp_move)\n",
        "      if v_temp > v:\n",
        "        v = v_temp\n",
        "        move = temp_move\n",
        "\n",
        "    return move"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6sV25snKcj1"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQD9UoYBKab1"
      },
      "source": [
        "class Trainer():\n",
        "\n",
        "  def __init__(self, game, params, lrnf, expf):\n",
        "    self.game = game\n",
        "    self.agent_p1 = Agent(1,params,game,lrnf,expf)\n",
        "    self.agent_p2 = Agent(-1,params,game,lrnf,expf)\n",
        "\n",
        "    self.agents = [self.agent_p1,self.agent_p2]\n",
        "\n",
        "  def train_agents(self):\n",
        "    \n",
        "    self.game.reset_game()\n",
        "    iter = 0\n",
        "    while not self.game.check_win():\n",
        "      move = self.agents[iter%2].make_move()\n",
        "      self.agents[iter%2].train_network()\n",
        "      self.game.make_move(move)\n",
        "      iter+=1\n",
        "    self.agents[0].train_network()\n",
        "    self.agents[1].train_network()\n",
        "    self.agents[0].train_network()\n",
        "    self.agents[1].train_network()\n",
        "      \n",
        "\n",
        "  def test_agent(self, loops, player):\n",
        "    win_list = []\n",
        "\n",
        "    for loop in range(loops):\n",
        "      self.game.reset_game()\n",
        "      iter = 0\n",
        "      while not self.game.check_win():\n",
        "        if iter%2 == player:\n",
        "          move = self.agents[iter%2].make_move(exploit=True)\n",
        "        else:\n",
        "          move = self.agents[iter%2].make_move(explore=True)\n",
        "\n",
        "        self.game.make_move(move)\n",
        "        iter+=1\n",
        "        \n",
        "      win_list.append(self.game.get_winner())\n",
        "      \n",
        "\n",
        "    wins_1 = win_list.count(1)\n",
        "    wins_2 = win_list.count(-1)\n",
        "    ties = win_list.count(0)\n",
        "\n",
        "    if player == 0:\n",
        "      print(\" , player1 prc: \" + str(wins_1/loops) , end = \"\")\n",
        "    else:\n",
        "      print(\" , player2 prc: \" + str(wins_2/loops) , end = \"\")\n",
        "\n",
        "  def spar_agents(self, loops):\n",
        "    win_list = []\n",
        "\n",
        "    for loop in range(loops):\n",
        "      self.game.reset_game()\n",
        "      iter = 0\n",
        "      while not self.game.check_win():\n",
        "        move = self.agents[iter%2].make_move()\n",
        "        self.game.make_move(move)\n",
        "        iter+=1\n",
        "        \n",
        "      win_list.append(self.game.get_winner())\n",
        "      \n",
        "\n",
        "    wins_1 = win_list.count(1)\n",
        "    wins_2 = win_list.count(-1)\n",
        "    ties = win_list.count(0)\n",
        "\n",
        "    print(\" , player1 prc: \" + str(wins_1/loops) , end = \"\")\n",
        "    print(\" , player2 prc: \" + str(wins_2/loops))\n",
        "\n",
        "  def tune_agents(self, exp1, epx2, lrn1, lrn2):\n",
        "    self.agents[0].change_factors(lrn1, exp1)\n",
        "    self.agents[1].change_factors(lrn2, epx2)\n",
        "\n",
        "  def save_agent(self, player, path):\n",
        "    model = self.agents[player].get_model()\n",
        "    model.save(path)\n",
        "\n",
        "  def load_agent(self, player, path):\n",
        "    self.agents[player].load_model(path)\n",
        "\n",
        "  def watch_game(self):\n",
        "    self.game.reset_game()\n",
        "\n",
        "    iter = 0\n",
        "    while not self.game.check_win():\n",
        "      print(\"~~~~~~~~~~~~~~~~~~~~~\")\n",
        "      self.game.print_game()\n",
        "      move = self.agents[iter%2].make_move()\n",
        "      self.game.make_move(move)\n",
        "      iter+=1\n",
        "    print(\"~~~~~~~~~~~~~~~~~~~~~\")\n",
        "    self.game.print_game()\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFin2xbCb86M"
      },
      "source": [
        "Manager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_MRp102aeyB"
      },
      "source": [
        "class Manager():\r\n",
        "  def __init__(self):\r\n",
        "    self.game = None\r\n",
        "    self.trainer = None\r\n",
        "\r\n",
        "  def set_game(self, class_name):\r\n",
        "    try:\r\n",
        "      game_class = getattr(sys.modules[__name__], class_name)\r\n",
        "    except AttributeError:\r\n",
        "      print(\"Class not found.\")\r\n",
        "      return\r\n",
        "\r\n",
        "    try:\r\n",
        "      self.game = game_class()\r\n",
        "\r\n",
        "      self.game.make_move(self.game.get_state())\r\n",
        "      self.game.check_win()\r\n",
        "      self.game.get_moves(self.game.get_state(),1)\r\n",
        "      self.game.get_reward(1)\r\n",
        "      self.game.get_winner()\r\n",
        "      self.game.reset_game()\r\n",
        "      self.game.print_game()\r\n",
        "    except:\r\n",
        "      print(\"Class missing required functions.\")\r\n",
        "      self.game = None\r\n",
        "    \r\n",
        "    \r\n",
        "  def set_trainer(self, layers, lrnf, expf):\r\n",
        "    \r\n",
        "    try:\r\n",
        "      if self.game == None:\r\n",
        "        print(\"Game is not defined.\")\r\n",
        "        return\r\n",
        "      self.trainer = Trainer(self.game, layers, lrnf, expf)\r\n",
        "    except:\r\n",
        "      print(\"Incorrect parameters.\")\r\n",
        "      self.trainer = None\r\n",
        "    \r\n",
        "  def train_agents(self, loops):\r\n",
        "    for i in range(loops):\r\n",
        "      self.trainer.train_agents()\r\n",
        "\r\n",
        "  def test_agents(self, loops):\r\n",
        "    self.trainer.test_agent(loops,0)\r\n",
        "    self.trainer.test_agent(loops,1)\r\n",
        "\r\n",
        "  def get_trainer(self):\r\n",
        "    return self.trainer\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKqkxCWpdCMW"
      },
      "source": [
        "# Games Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5_Sl-eDrdMY"
      },
      "source": [
        "Prisoner's Dilemma\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdxgiVuorc3Y"
      },
      "source": [
        "#SCORES:\r\n",
        "#    | 1 |-1 |\r\n",
        "#  1 |3,3|0,5|\r\n",
        "# -1 |5,0|1,1|\r\n",
        "\r\n",
        "class PriDilemma():\r\n",
        "\r\n",
        "  def __init__ (self):\r\n",
        "    self.state = [0,0,0,0,0,0,0,\r\n",
        "                  0,0,0,0,0,0,0]\r\n",
        "    self.mirrorGame = [0,0,0,0,0,0,0,\r\n",
        "                       0,0,0,0,0,0,0]\r\n",
        "    self.tempMoves = [0,0]\r\n",
        "    self.winner = 0\r\n",
        "    self.player = 1\r\n",
        "    self.turn = 0\r\n",
        "    self.playerScores = [0,0]\r\n",
        "    self.mirrorScores = [0,0]\r\n",
        "    \r\n",
        "  def reset_game(self): #mandatory: reset board\r\n",
        "    self.state = [0,0,0,0,0,0,0,\r\n",
        "                  0,0,0,0,0,0,0]\r\n",
        "    self.mirrorGame = [0,0,0,0,0,0,0,\r\n",
        "                       0,0,0,0,0,0,0]\r\n",
        "    self.tempMoves = [0,0]\r\n",
        "    self.winner = 0\r\n",
        "    self.player = 1\r\n",
        "    self.turn = 0\r\n",
        "    self.playerScores = [0,0]\r\n",
        "    self.mirrorScores = [0,0]\r\n",
        "\r\n",
        "  def make_move(self, new_state): #mandatory: in board state after move \r\n",
        "    spots = {1:0,-1:1}\r\n",
        "    jump = 0\r\n",
        "    if self.player == -1:\r\n",
        "      jump = 7\r\n",
        "\r\n",
        "    self.tempMoves[spots[self.player]] = new_state[self.turn+jump]\r\n",
        "    self.player *= -1\r\n",
        "\r\n",
        "    if self.player == 1:\r\n",
        "      self.state[self.turn] = self.tempMoves[0]\r\n",
        "      self.state[self.turn+7] = self.tempMoves[1]\r\n",
        "      self.make_mirror_move()\r\n",
        "      self.find_scores()\r\n",
        "      self.turn += 1\r\n",
        "\r\n",
        "  def make_mirror_move(self):\r\n",
        "    p = random.uniform(0,1)\r\n",
        "    if p > 0.8:\r\n",
        "      self.mirrorGame[self.turn] = random.choice([-1,1])\r\n",
        "    else:\r\n",
        "      self.mirrorGame[self.turn] = self.tempMoves[0]*-1\r\n",
        "\r\n",
        "    p = random.uniform(0,1)\r\n",
        "    if p > 0.8:\r\n",
        "      self.mirrorGame[self.turn+7] = random.choice([-1,1])\r\n",
        "    else:\r\n",
        "      self.mirrorGame[self.turn+7] = self.tempMoves[1]*-1\r\n",
        "\r\n",
        "    \r\n",
        "  def check_win(self): #mandatory: return if game is finished\r\n",
        "    if 0 in self.state:\r\n",
        "      return False\r\n",
        "    self.find_winner()\r\n",
        "    return True\r\n",
        "\r\n",
        "  def get_moves(self, state, player): #mandatory: return all possible board states after 'player' moves, in 'state'\r\n",
        "    move_set = []\r\n",
        "    jump = 0\r\n",
        "    if player == -1:\r\n",
        "      jump = 7\r\n",
        "\r\n",
        "    while isinstance(state[0], list):\r\n",
        "      state = state[0]\r\n",
        "\r\n",
        "    iter = self.turn\r\n",
        "     \r\n",
        "    move_set.append(state[:iter+jump] + [-1] + state[iter+1+jump:])\r\n",
        "    move_set.append(state[:iter+jump] + [1] + state[iter+1+jump:])\r\n",
        "\r\n",
        "    return move_set\r\n",
        "\r\n",
        "  def get_state(self): #mandatory: return board state\r\n",
        "    return self.state\r\n",
        "\r\n",
        "  def get_reward(self, player): #mandatory: return rewards for curent board state for 'player'\r\n",
        "    spots = {1:0,-1:1}\r\n",
        "    reward = 0\r\n",
        "\r\n",
        "    if self.mirrorScores[spots[player]] >= self.playerScores[spots[player]]:\r\n",
        "      reward -= 1\r\n",
        "    else:\r\n",
        "      reward += 0.5\r\n",
        "\r\n",
        "    if self.playerScores[spots[player*-1]] > self.playerScores[spots[player]]:\r\n",
        "      reward -= 0.5\r\n",
        "    else:\r\n",
        "      reward += 1\r\n",
        "\r\n",
        "    return reward\r\n",
        "    \r\n",
        "\r\n",
        "  def get_winner(self): #mandatory: return winner\r\n",
        "    return self.winner\r\n",
        "\r\n",
        "  def find_winner(self):\r\n",
        "    if self.playerScores[0] > self.playerScores[1]:\r\n",
        "      self.winner = 1\r\n",
        "    elif self.playerScores[0] < self.playerScores[1]:\r\n",
        "      self.winner = -1\r\n",
        "\r\n",
        "  def find_scores(self):\r\n",
        "    iter = self.turn\r\n",
        "\r\n",
        "    if self.state[iter] == 1 and self.state[iter+7] == 1:\r\n",
        "      self.playerScores[0] += 3\r\n",
        "      self.playerScores[1] += 3\r\n",
        "    elif self.state[iter] == 1 and self.state[iter+7] == -1:\r\n",
        "      self.playerScores[0] += 0\r\n",
        "      self.playerScores[1] += 5\r\n",
        "    elif self.state[iter] == -1 and self.state[iter+7] == 1:\r\n",
        "      self.playerScores[0] += 5\r\n",
        "      self.playerScores[1] += 0\r\n",
        "    else:\r\n",
        "      self.playerScores[0] += 1\r\n",
        "      self.playerScores[1] += 1\r\n",
        "    \r\n",
        "    if self.mirrorGame[iter] == 1 and self.mirrorGame[iter+7] == 1:\r\n",
        "      self.mirrorScores[0] += 3\r\n",
        "      self.mirrorScores[1] += 3\r\n",
        "    elif self.mirrorGame[iter] == 1 and self.mirrorGame[iter+7] == -1:\r\n",
        "      self.mirrorScores[0] += 0\r\n",
        "      self.mirrorScores[1] += 5\r\n",
        "    elif self.mirrorGame[iter] == -1 and self.mirrorGame[iter+7] == 1:\r\n",
        "      self.mirrorScores[0] += 5\r\n",
        "      self.mirrorScores[1] += 0\r\n",
        "    else:\r\n",
        "      self.mirrorScores[0] += 1\r\n",
        "      self.mirrorScores[1] += 1\r\n",
        "\r\n",
        "  def print_game(self): #mandatory: print game board\r\n",
        "    syms = ['C' if x==1 else 'D' if x==-1 else ' ' for x in self.state]\r\n",
        "      \r\n",
        "    for sym in syms[:7]:\r\n",
        "      print(sym , end = \"|\")\r\n",
        "    print(\"\")\r\n",
        "    for sym in syms[7:]:\r\n",
        "      print(sym , end = \"|\")\r\n",
        "    print(\"\\n--------------\")\r\n",
        "  \r\n",
        "  def print_mirror(self):\r\n",
        "    syms = ['C' if x==1 else 'D' if x==-1 else ' ' for x in self.mirrorGame]\r\n",
        "      \r\n",
        "    for sym in syms[:7]:\r\n",
        "      print(sym , end = \"|\")\r\n",
        "    print(\"\")\r\n",
        "    for sym in syms[7:]:\r\n",
        "      print(sym , end = \"|\")\r\n",
        "    print(\"\\n--------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb87WEMSbUtG"
      },
      "source": [
        "TicTacToe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7JXx8pF_H2A"
      },
      "source": [
        "class TicTacToe():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.state = [0,0,0,\n",
        "                  0,0,0,\n",
        "                  0,0,0]\n",
        "    self.winner = 0\n",
        "    self.player = 1\n",
        "    self.turn = 0\n",
        "\n",
        "  def reset_game(self): #mandatory: reset board\n",
        "    self.state = [0,0,0,\n",
        "                  0,0,0,\n",
        "                  0,0,0]\n",
        "    self.winner = 0\n",
        "    self.player = 1\n",
        "    self.turn = 0\n",
        "\n",
        "  def make_move(self, new_state): #mandatory: in board state after move \n",
        "    self.state = new_state\n",
        "    self.turn += 1\n",
        "    self.player *= -1\n",
        "\n",
        "  def check_win(self): #mandatory: return if game is finished\n",
        "    if self.check_win_cond() or self.check_tie():\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def get_moves(self, state, player): #mandatory: return all possible board states after 'player' moves, in 'state'\n",
        "    move_set = []\n",
        "\n",
        "    while isinstance(state[0], list):\n",
        "      state = state[0]\n",
        "\n",
        "    for i in range(9):\n",
        "      if state[i] == 0:\n",
        "        move_set.append(state[:i] + [player] + state[i+1:])\n",
        "    \n",
        "    return move_set\n",
        "\n",
        "  def get_state(self): #mandatory: return board state\n",
        "    return self.state\n",
        "\n",
        "  def get_reward(self, player): #mandatory: return rewards for curent board state for 'player'\n",
        "    if self.winner == player:\n",
        "      return 1\n",
        "    elif self.winner == 0:  \n",
        "      return 0.5\n",
        "    elif self.winner is None:\n",
        "      return 0\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  def get_winner(self): #mandatory: return winner\n",
        "    return self.winner\n",
        "\n",
        "  def check_win_cond(self):\n",
        "    win_pos = [[0,1,2],[3,4,5],[6,7,8],[0,3,6],[1,4,7],[2,5,8],[0,4,8],[2,4,6]]\n",
        "    \n",
        "    for pos in win_pos:\n",
        "      conf = [self.state[pos[0]] , self.state[pos[1]] , self.state[pos[2]]]\n",
        "      if conf == [1,1,1]:\n",
        "        self.winner = 1\n",
        "        return True\n",
        "      elif conf == [-1,-1,-1]:\n",
        "        self.winner = -1\n",
        "        return True\n",
        "      \n",
        "    return False;\n",
        "\n",
        "  def check_tie(self):\n",
        "    if self.turn >= 9:\n",
        "      self.winner = 0\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def print_game(self): #mandatory: print game board\n",
        "    syms = ['X' if x==1 else 'O' if x==-1 else ' ' for x in self.state]\n",
        "    print(\"\\n\"+syms[0]+\"|\"+syms[1]+\"|\"+syms[2])\n",
        "    print(\"-----\")\n",
        "    print(syms[3]+\"|\"+syms[4]+\"|\"+syms[5])\n",
        "    print(\"-----\")\n",
        "    print(syms[6]+\"|\"+syms[7]+\"|\"+syms[8])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvULTRIdceR2"
      },
      "source": [
        "# Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAkXVPbxeoPc"
      },
      "source": [
        "#@title Initialize Game. Type in games class name. Example class_name: \"TicTacToe\"\n",
        "class_name = \"TicTacToe\" #@param {type:\"string\"}\n",
        "manager = Manager()\n",
        "manager.set_game(class_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLw1CYFAro24"
      },
      "source": [
        "#@title Initialize Trainer. Example layers: \"18,9\"\n",
        "layers = \"18,9\" #@param {type:\"string\"}\n",
        "exploration_factor = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "learning_factor = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "try:\n",
        "  layers = layers.split(\",\")\n",
        "  layers = [int(x) for x in layers]\n",
        "except:\n",
        "  print(\"Invalid layers input.\")\n",
        "\n",
        "manager.set_trainer(layers,learning_factor,exploration_factor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4LMbzotZPdJ"
      },
      "source": [
        "#@title Load model from file. 0 - first player, 1 - second player.\n",
        "file_name = \"player1\" #@param {type:\"string\"}\n",
        "player_number =  0#@param {type:\"integer\"}\n",
        "\n",
        "manager.get_trainer().load_agent(player_number, file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w7Y35Mi-ojN"
      },
      "source": [
        "#@title Change exploration and lerning factors of agents.\n",
        "player1_exp_factor = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "player1_lrn_factor = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "player2_exp_factor = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "player2_lrn_factor = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "manager.get_trainer().tune_agents(player1_exp_factor, player2_exp_factor, player1_lrn_factor, player2_lrn_factor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YWp0khz_ha2"
      },
      "source": [
        "#@title Train agents.\n",
        "global_loops = 20 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "training_loops = 50 #@param {type:\"slider\", min:0, max:500, step:5}\n",
        "testing_loops = 200 #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "\n",
        "for i in range(global_loops):\n",
        "  print(\"\\nLoop \", i+1,end = \": \")\n",
        "  manager.train_agents(training_loops)\n",
        "  if testing_loops>0:\n",
        "    manager.test_agents(testing_loops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULyoviC3FlM0"
      },
      "source": [
        "#@title Spar agents.\n",
        "loops = 1000 #@param {type:\"integer\"}\n",
        "\n",
        "manager.get_trainer().spar_agents(loops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "035W16iJUoWF"
      },
      "source": [
        "#@title Save model to file. 0 - first player, 1 - second player.\n",
        "file_name = \"player1\" #@param {type:\"string\"}\n",
        "player_number =  0#@param {type:\"integer\"}\n",
        "manager.get_trainer().save_agent(player_number, file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeGUnJD3wFHX"
      },
      "source": [
        "#@title Watch one game between agents. \n",
        "manager.get_trainer().watch_game()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}